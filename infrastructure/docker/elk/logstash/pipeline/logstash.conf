# Logstash Pipeline Configuration for AI Trading Bot
# Version: 7.17.0
# Purpose: Advanced log processing pipeline for trading system events and metrics

input {
  beats {
    port => 5044
    host => "0.0.0.0"
    
    ssl => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    ssl_verify_mode => "force_peer"
  }
}

filter {
  # Parse JSON structured logs
  json {
    source => "message"
    target => "parsed_log"
    skip_on_invalid_json => true
  }

  # Trading system specific Grok patterns
  grok {
    patterns_dir => "/usr/share/logstash/patterns"
    match => {
      "message" => [
        # Trade execution pattern
        "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:service}\] Trade execution - pair:%{DATA:trading_pair} latency:%{NUMBER:execution_latency:float}ms price:%{NUMBER:price:float} amount:%{NUMBER:amount:float}",
        
        # Strategy optimization pattern
        "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:service}\] Strategy optimization cycle completed - duration:%{NUMBER:optimization_duration:float}s strategy:%{DATA:strategy_name}",
        
        # Portfolio rebalancing pattern
        "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:service}\] Portfolio rebalancing - duration:%{NUMBER:rebalancing_duration:float}s status:%{WORD:status}",
        
        # ML model update pattern
        "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:service}\] ML model update - duration:%{NUMBER:model_update_duration:float}s model:%{DATA:model_name}"
      ]
    }
  }

  # Add performance tags based on thresholds
  ruby {
    code => "
      event.set('performance_tags', [])
      tags = event.get('performance_tags')
      
      if event.get('execution_latency') && event.get('execution_latency') > 500
        tags << 'high_latency'
      end
      
      if event.get('optimization_duration') && event.get('optimization_duration') > 300
        tags << 'slow_optimization'
      end
      
      if event.get('rebalancing_duration') && event.get('rebalancing_duration') > 30
        tags << 'slow_rebalancing'
      end
      
      if event.get('model_update_duration') && event.get('model_update_duration') > 3600
        tags << 'delayed_model_update'
      end
      
      event.set('performance_tags', tags)
    "
  }

  # Add timestamp for time-based analysis
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }

  # Enrich logs with additional context
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:production}"
      "app" => "ai_trading_bot"
    }
    convert => {
      "execution_latency" => "float"
      "optimization_duration" => "float"
      "rebalancing_duration" => "float"
      "model_update_duration" => "float"
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "trading-logs-%{+YYYY.MM.dd}"
    document_type => "_doc"
    
    # Bulk insertion optimization
    bulk_size => 5000
    bulk_timeout => "3s"
    
    # Retry configuration
    retry_on_conflict => 3
    action => "index"
    
    # Template configuration
    template_name => "trading-logs"
    template_overwrite => true
    
    # ILM Policy
    ilm_enabled => true
    ilm_rollover_alias => "trading-logs"
    ilm_pattern => "{now/d}-000001"
    ilm_policy => "trading-logs-policy"
  }

  # Debug output for development (disabled in production)
  if [log_level] == "DEBUG" {
    stdout {
      codec => rubydebug
    }
  }
}

# Pipeline performance monitoring
pipeline.batch.size: 5000
pipeline.batch.delay: 50
pipeline.workers: 4
pipeline.output.workers: 4
queue.type: persisted
queue.max_bytes: 1gb